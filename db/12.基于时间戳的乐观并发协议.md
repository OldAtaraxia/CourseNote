`"锁"的问题: 影响性能, 悲观. Timestamp ordering(T/O)则是乐观的

基于时间戳的事务模型，在每一个事务开始的时候，就给它分配一个时间戳，通过时间戳在一个事务开始前就决定了其执行顺序。基于 T/0 的事务通常是**乐观事务模型**。

若$TS(T_i) < TS(T_j)$, 则DBMS需要保证最后的结果等价于串行执行且$T_i$的执行顺序在$T_j$之前

---

## 理论基础

> CMU这一部分讲得真的好乱啊...

* 所谓的依赖关系/冲突关系

有三种: 读写, 写读, 读读. 冲突关系是用来表征事务之间的顺序的.

比如写读中, T2读到了T1写的数据, 就说明T2在T1之后. 

当serialization graph中没有环时, 调度就是可串行化的.

* 事务的可恢复性: 即committed的事务不会被未提交的事务的失败影响.

比如T2读到了T1的写并提交了, 这是如果T1回滚, 就会导致对T2造成不可恢复的影响.

* 联级回滚（cascading abort) : 在T1失败时，所有和T1有依赖链的未提交事务都要回滚。

> 为了避免这种由"脏读"引起的现象, 一般在Read Committed隔离级别下就禁止脏读出现

---

## 时间戳

分配时间戳的策略:

* 系统事件, 单机可行, 分布式不可行(难以同步)
* logic counter: 逻辑时间，比如自增 ID，能保证每一个 txn 有一个唯一的时间戳，但是和现实时间割裂。但是在分布式情景下难以同步.
* Hybrid. 前两者混合

## Basic T/O

> TO规则：数据管理器将按照时间戳的大小，依次执行冲突的操作。这样相当于规定了事务发生的次序

读写都不需要加锁.

给每一个事务附上一个唯一的时间戳, 每一条记录附上两个时间戳:

- W-TS(X)，item X 上最近的一次写入事务的时间戳。
- R-TS(X)，item X 上最新的一次读取事务的时间戳。

事务每次进行操作时都先要检查时间戳, 宗旨是"不能操作来自未来的数据"

* 读时, 比较当前事务的时间戳与**写时间戳**, 若$TS(T_i) < W_{TS(X)}$(被后来的事务已经写过了), 当前事务abort然后restart
  * 否则就正常读取`x`并更新读时间戳$R_{TS(X)}$​​为原更新时间戳与当前事务时间戳的更大值. 同时把数据`x`拷贝到本地作副本, 保证当前事务之后读它时读到的是快照



* 写时, 分别比较当前事务的时间戳与**数据的读/写时间戳**, 如果 TS(Ti)<RTS(X) 或 TS(Ti)<WTS(X), (被后来的事务读过或写过了), 当前事务abort然后restart

> 总结: 不能读未来事务才会写的内容、不能覆写未来事务读过或写过的内容. 否则当前事务重启

---

### Thomas's Write rule

* 优化: Thomas's Write Rule. 若S(Ti)<RTS(X)则当前事务abort然后restart, 但如果TS(Ti)<WTS(X), 忽略掉当前的写请求

> 不能覆写未来事务读过, 但可以假设未来事务把自己的写操作覆盖掉了.

例子中T1的写操作理论上是不能执行的, 但按照T1 -> T2的串行化顺序执行的话T1的写操作最后会被T2的写操作覆盖掉. 因此是等效的

![image-20220314095841997](https://gitee.com/oldataraxia/pic-bad/raw/master/img/image-20220314095841997.png)

### 问题 

> * 存在一个长事务被连续不断到来的短事务 **starve** 的可能。
> * 每一个事务都需要独立拷贝数据到自己独立空间，会带来一定的负担。
> * 存在产生 unrecoverable schedule 的可能, 比如下图T2 脏读了未提交的 A, 这时若T1回滚则完蛋, T2是不可恢复的.
>
> ![image-20220314100455834](https://gitee.com/oldataraxia/pic-bad/raw/master/img/image-20220314100455834.png)
>
> 实际上没有数据库会采用 Basic T/O 的方式来实现乐观的并发控制。

严格的实现为了保证revocerability会禁止掉脏读. 

## Optimistic Concurrency Control(OCC)

乐观并发控制/基于有效性检查的协议, 悲观算法下的执行过程：

```text
|有效性验证|-->|读|-->|计算|-->|写|
```

而乐观算法是将有效性验证的操作移到写操作之前，如下所示：

```text
|读|-->|计算|-->|有效性验证|-->|写|
```

---

每个事务都有一个**私有空间**，事务将读到的内容临时存放在私有空间，随后对私有空间中的值做修改。当事务执行完后，数据库根据事务的时间戳和临时空间中的读写内容判断事务之间是否发生冲突，若没有发生冲突再将事务的所有修改写入数据库。

过程:

* Read: 读取数据保存在当前事务的独立空间里，修改也是在该空间中进行。因此这个阶段对于数据库来说是只读的.

> 这个阶段所能读到的数据一定都是被commit的, 也就是说一定不会产生脏读的现象

* Validation: 当事务 commit 时，检查其独立空间中的值是否会和数据库里的冲突。判断是否需要 abort 并 restart。**在校验阶段赋予事务时间戳, 未进入校验阶段的事务的时间戳视为正无穷**.

> 这里课上讲的也太迷惑了, 就按照数据库系统概念中所讲的来吧

* Write: 如果 validation phase 检查成功，执行 write phase，把自己空间里的值写入数据库。只读事务没有这个阶段. 写阶段一般会锁全表来防止奇特的并发错误.

例子: T1和T2分别把A赋值到自己的Workspace中, T1还要进行修改

![image-20220314101754400](https://gitee.com/oldataraxia/pic-bad/raw/master/img/image-20220314101754400.png)

### validation阶段

> 课上讲的也太迷惑了

每个事务需要与三个时间戳关联：

* $StartTS（T_i)$, 即事务开始执行的时间
* $ValidationTS(T_i)$, 事务完成其读阶段并开始其有效性检查的时间
* $FinishTS(T_i)$: 事务完成其写阶段的时间

最后取$TS(T_i) = ValidationTS(T_i)$, 以其作为最后时间戳的代表.

参考数据库系统概念第七版中的说法, 事务$T_i$的有效性检查测试要求满足$TS(T_k) < TS(T_i)$的所有事务$T_k$必须满足以下两个条件中的一个:

* $FinishTS(T_k) < StartTS(T_i)$, 即$T_k$在$T_i$开始之前就已经执行完成
* $StartTS（T_i) < FinishTS(T_k) < ValidationTS(T_i)$​(即$T_k$在$T_i$开始有效性检查之前就完成了其写阶段), 且$T_k$所写的数据项集合与$T_i$所读的数据项集合不相交.

### 例子

事务T1读取A时，将A复制到自己的私有空间中，可以看到，与上一个方案相比，OCC 只需要记录一个时间戳，W-TS。



![img](https://gitee.com/oldataraxia/pic-bad/raw/master/img/v2-dc1603719918d1571a427efd994f3b19_720w.jpg)



事务T2 读取 A 时，同样将 A 复制到自己的私有空间中：



![img](https://pic1.zhimg.com/80/v2-49ab8b8b40f726104e016cb00ecae304_720w.jpg)



事务T2 完成数据操作，在有效性检查阶段中获得事务时间戳 1，由于没有数据写入，跳过写阶段



![img](https://pic2.zhimg.com/80/v2-718d1f331b10954b9d1c89a40d542f65_720w.jpg)



事务T1 修改 A 的值为 456，由于尚不知道自己的事务时间戳，将 W-TS(A) 设置为无穷大：



![img](https://pic2.zhimg.com/80/v2-d1fb425435c61442eee846bf66b7e58d_720w.jpg)



事务T1 在有效性检查阶段获得事务时间戳 2，并通过校验，将 W-TS(A) 修改为 2，并合并到数据库中



![img](https://pic1.zhimg.com/80/v2-4b547e6c833549ac8908b31068398078_720w.jpg)

### 适用场景

数据库规模很大, 查询很均匀的时候, 因为冲突概率很小, 加锁的cost会很低, 加锁会很浪费

### 问题

* 把数据拷贝到本地需要开销
* 校验是一个比较复杂的逻辑, 是瓶颈, 尤其是经常冲突的时候, 因为其中设计到一些latch的问题, 要锁住其它事务的私有空间对比是否有冲突)
* 写过程不能并发
* 事务的终止会导致比2PL更大的性能影响, 因为OCC在事务执行快结束时才检查数据冲突. 可能会**级联回滚**



---

## 幻读

之前锁讨论的都是read和update操作, 其实Insert和delete会导致问题. 当事务中出现Insert操作时, 2PL和OCC都不能保证调度的可串行性, 可能会导致**幻读(第二次读到了第一次不存在的东西)**问题:

![image-20220314203522196](https://gitee.com/oldataraxia/pic-bad/raw/master/img/image-20220314203522196.png)

> 原因: 锁只能锁现存的记录, 而不能控制插入的新记录. 而锁住整个表又会产生新的性能问题.

### Re-execution scans

记录所有可能产生幻读的部分(`where`语句) . 在commit时再次扫描, 查看数据有没有变化.

### Predicate locking

- 为select语句则加共享锁
- 为update,delete,insert则加排他锁
- 这样假如有`select`为某个谓词加了共享锁, insert想要插入对应数据时就无法获得排它锁, 进而就无法实现数据插入了.

![image-20220314204805934](https://gitee.com/oldataraxia/pic-bad/raw/master/img/image-20220314204805934.png)

### index locking

如果在 `status` 字段上有索引，那么我们可以锁住包含 `status = 'lit'` 的索引页。如果尚未存在这样的数据，我们也需要锁住可能对应的索引页。

> MySQL: 间隙锁, 把数据分为数据和间隙, 比如数据为1 ,3, 5, 7, 9, MySQL会把1到3之间的间隙也看作数据, 如果要锁这段数据, 那么间隙也会被锁上.
>
> 有些select不一定有`where`子句, 如`SELECT MAX()`, 会把之前的最大值到正无穷的间隙也锁上

如果没有索引:



